# import lib.2s
# import buffered_stdin.2s
# import byte_vector.2s
# import array_list.2s
# import stack_effect.2s
# import switch_stmt.2s

# <word name> -> <bool>
def "does_word_exist" {
    dip { drop } drop
    while { lazy_and { not = 0 dup } not over } {
        stacktrace_dict_record_next
        keep { string_equals stacktrace_dict_record_name dip { dup } }
        dip { drop }
    }
    stacktrace_def_list false
} ;

# <name> <func> ->
def "shadow_def" {
    write_mem_i64 the_dictionary
    keep { write_mem_i64 + 16 dip { stacktrace_def_list } } # next
    keep { write_mem_i64 } # name
    keep { write_mem_i64 + 8 } # word_def
    malloc 24
    keep { write_mem_i64 + 8 dip { true } } # is_function = true
    keep { write_mem_i64 }
    malloc 16
    swap
} ;

# <name> <func> ->
shadow_def "def" {
    shadow_def
    if { does_word_exist dup } {
        exit 1
        print_newline
        print_string "' is already defined"
        print_string dup
        print_string "word '"
    } { }
} ;

# <name> <value> ->
shadow_def "constant" {
    def swap func_capture swap
} ;

def "print_char_ord" {
    print_newline
    . read_mem_byte read_mem_i64 + 16
    print_string "' is " print_string dup print_string "char '"
} ;

def "string_first_char" {
    byte_vector_get dip { 0 }
} ;

constant "open_bracket_char" string_first_char "{" ;
constant "close_bracket_char" string_first_char "}" ;
constant "semicolon_char" string_first_char ";" ;
constant "space_char" string_first_char " " ;
constant "tab_char" string_first_char "\t" ;
constant "newline_char" string_first_char "\n" ;
constant "double_quote_char" 34 ;
constant "single_quote_char" 39 ;
constant "backslash_char" 92 ;

# <char> -> <bool>
def "is_whitespace_char" {
    drop swap
    lazy_or { lazy_or { = space_char dup } = tab_char dup } = newline_char dup
} ;
def "skip_whitespace" {
    while { is_whitespace_char } {
        buffered_stdin_peek_byte
        drop buffered_stdin_read_byte
    }
    buffered_stdin_peek_byte
} ;


# token layout
# [type id] [value]
# types:
# 0 - {{ 
# 1 - }} 
# 2 - {
# 3 - }
# 4 - string literal, value is string
# 5 - char literal, value is string
# 6 - word or i64 literal, value is string
# 7 - ;

constant "token_double_open_bracket_type"   0 ;
constant "token_double_close_bracket_type"  1 ;
constant "token_open_bracket_type"          2 ;
constant "token_close_bracket_type"         3 ;
constant "token_string_literal_type"        4 ;
constant "token_char_literal_type"          5 ;
constant "token_word_or_i64_literal_type"   6 ;
constant "token_semicolon_type"             7 ;

# <expr type id> <value> -> <token>
def "token_create" {
    keep { write_mem_i64 + 8 }
    keep { write_mem_i64 }
    malloc * 2 8
} ;
 
# <expr> -> <token type id>
def "token_get_type_id" {
    read_mem_i64
} ;

# <expr> -> <value>
def "token_get_value" {
    read_mem_i64 + 8
} ;

def "token_print_switch"
    when { = token_semicolon_type dup } then { print_string "semicolon" 2drop } otherwise
    when { = token_word_or_i64_literal_type dup } then { print_string "'" print_string token_get_value print_string "word or i64 literal: '" drop } otherwise
    when { = token_char_literal_type dup } then { print_string "'" print_string token_get_value print_string "char literal: '" drop } otherwise
    when { = token_string_literal_type dup } then { print_string "'" print_string token_get_value print_string "string literal: '" drop } otherwise
    when { = token_close_bracket_type dup } then { print_string "close paren" 2drop } otherwise
    when { = token_open_bracket_type dup } then { print_string "open bracket" 2drop } otherwise
    when { = token_double_close_bracket_type dup } then { print_string "double close bracket" 2drop } otherwise
    when { = token_double_open_bracket_type dup } then { print_string "double open bracket" 2drop } otherwise
    { assert "bad token type" false 2drop . dup }
;

# <token> ->
def "token_print" {
    token_print_switch
    token_get_type_id dup
} ;

def "token_destroy_switch"
    when { = token_semicolon_type dup } then { free drop } otherwise
    when { = token_word_or_i64_literal_type dup } then {
        bi { free } { byte_vector_destroy token_get_value } drop
    } otherwise
    when { = token_char_literal_type dup } then {
        bi { free } { byte_vector_destroy token_get_value } drop
    } otherwise
    when { = token_string_literal_type dup } then {
        bi { free } { byte_vector_destroy token_get_value } drop
    } otherwise
    when { = token_close_bracket_type dup } then { free drop } otherwise
    when { = token_open_bracket_type dup } then { free drop } otherwise
    when { = token_double_close_bracket_type dup } then { free drop } otherwise
    when { = token_double_open_bracket_type dup } then { free drop } otherwise
    { assert "bad token type" false 2drop . dup }
;

# <token> ->
def "token_destroy" {
    token_destroy_switch
    token_get_type_id dup
} ;
se_check_last_defined_function ;

def "scanner_peek" {
    buffered_stdin_peek_byte
} ;

def "scanner_advance" {
    drop buffered_stdin_read_byte
} ;

# <string> -> <token>
def "read_next_token_word_read_rest" {
    token_create token_word_or_i64_literal_type
    while { not is_whitespace_char scanner_peek } {
        scanner_advance
        keep { byte_vector_append dip { scanner_peek } } 
    }
} ;
# -> <token> 
def "read_next_token_word" {
    read_next_token_word_read_rest
    byte_vector_new
} ;

# <char> -> <token> # first char is the arg, scanner on next char's position
def "read_next_token_word_1" {
    read_next_token_word_read_rest
    keep { byte_vector_append }
    byte_vector_new
} ;

# <char> <char> -> <token> # first 2 chars are args, scanner on next char's position
def "read_next_token_word_2" {
    read_next_token_word_read_rest
    keep { byte_vector_append }
    keep { byte_vector_append }
    byte_vector_new
} ;

# -> <token> # scanner on second bracket
def "read_next_token_double_open_bracket" {
    if { is_whitespace_char scanner_peek } {
        token_create token_double_open_bracket_type 0
    } {
        read_next_token_word_2 open_bracket_char open_bracket_char
    }
    scanner_advance
} ;

# -> <token>
def "read_next_token_open_bracket" {
    if { = open_bracket_char scanner_peek } {
        read_next_token_double_open_bracket
    } {
        if { is_whitespace_char scanner_peek } {
            token_create token_open_bracket_type 0
        } {
            read_next_token_word_1 open_bracket_char
        }
    }
    scanner_advance
} ;

# -> <token> # scanner on second bracket
def "read_next_token_double_close_bracket" {
    if { is_whitespace_char scanner_peek } {
        token_create token_double_close_bracket_type 0
    } {
        read_next_token_word_2 close_bracket_char close_bracket_char
    }
    scanner_advance
} ;

# -> <token>
def "read_next_token_close_bracket" {
    if { = close_bracket_char scanner_peek } {
        read_next_token_double_close_bracket
    } {
        if { is_whitespace_char scanner_peek } {
            token_create token_close_bracket_type 0
        } {
            read_next_token_word_1 close_bracket_char
        }
    }
    scanner_advance
} ;

# -> <token>
def "read_next_token_semicolon" {
    if { is_whitespace_char scanner_peek } {
        token_create token_semicolon_type 0
    } {
        read_next_token_word_1 semicolon_char
    }
    scanner_advance
} ;

def "is_double_quote_or_newline" { or bi { = double_quote_char } { = newline_char } } ;

# -> <token>
def "read_next_token_double_quote" {
    assert "whitespace after string literal" is_whitespace_char scanner_peek
    token_create token_string_literal_type
    scanner_advance
    assert "no newline in string literals" not = newline_char scanner_peek
    while { not is_double_quote_or_newline scanner_peek } {
        scanner_advance
        if { = backslash_char scanner_peek } {
            keep { byte_vector_append dip { scanner_peek } } 
            scanner_advance
        } { }
        keep { byte_vector_append dip { scanner_peek } } 
    }
    scanner_advance
    byte_vector_new
} ;

def "is_single_quote_or_newline" { or bi { = single_quote_char } { = newline_char } } ;

# -> <token>
def "read_next_token_single_quote" {
    assert "whitespace after char literal" is_whitespace_char scanner_peek
    token_create token_char_literal_type
    scanner_advance
    assert "no newline in char literals" not = newline_char scanner_peek
    while { not is_single_quote_or_newline scanner_peek } {
        scanner_advance
        if { = backslash_char scanner_peek } {
            keep { byte_vector_append dip { scanner_peek } } 
            scanner_advance
        } { }
        keep { byte_vector_append dip { scanner_peek } } 
    }
    scanner_advance
    byte_vector_new
} ;

# -> <token> # scanner on the char's position
def "read_next_token_switch"
    when { = open_bracket_char scanner_peek } then { read_next_token_open_bracket } otherwise
    when { = close_bracket_char scanner_peek } then { read_next_token_close_bracket } otherwise
#    when { = semicolon_char scanner_peek } then { read_next_token_semicolon } otherwise
    when { = double_quote_char scanner_peek } then { read_next_token_double_quote } otherwise
    when { = single_quote_char scanner_peek } then { read_next_token_single_quote } otherwise
    { read_next_token_word }
;

# -> <token>
def "read_next_token" {
    read_next_token_switch
    skip_whitespace
} ;
se_check_last_defined_function ;



# expression layout
# [type id] [value]
# types:
# 0 - quoted expressions {{ }}, value is expression list
# 1 - anon function { }, value is expression list
# 2 - i64 literal, value is i64
# 3 - string literal, value is string
# 4 - char literal, value is byte
# 5 - word, value is string

constant "expression_quoted_type" 0 ;
constant "expression_anon_func_type" 1 ;
constant "expression_i64_literal_type" 2 ;
constant "expression_string_literal_type" 3 ;
constant "expression_char_literal_type" 4 ;
constant "expression_word_type" 5 ;
# <expr type id> <value> -> <expression>
def "expression_create" {
    keep { write_mem_i64 + 8 }
    keep { write_mem_i64 }
    malloc * 2 8
} ;
 
# <expr> -> <token type id>
def "expression_get_type_id" {
    read_mem_i64
} ;

# <expr> -> <value>
def "expression_get_value" {
    read_mem_i64 + 8
} ;


# <list> ->
def "print_expression_list" {
    2drop
    while { > array_list_get_size 2dup } {
        dip { + 1 }
        print_newline
        expression_print array_list_get 2dup
    }
    dip { 0 }
} ;

def "expression_print_switch"
    when { = expression_word_type dup } then { print_string "'" print_string expression_get_value print_string "word: '" drop } otherwise
    when { = expression_string_literal_type dup } then { print_string "'" print_string expression_get_value print_string "string literal: '" drop } otherwise
    when { = expression_char_literal_type dup } then { print_string "'" write_byte_to_stdout expression_get_value print_string "char literal: '" drop } otherwise
    when { = expression_i64_literal_type dup } then { . expression_get_value print_string "i64 literal: " drop } otherwise
    when { = expression_anon_func_type dup } then { print_string "anon func:end" print_expression_list expression_get_value print_string "anon func:start\n" drop } otherwise
    when { = expression_quoted_type dup } then { print_string "quote:end" print_expression_list expression_get_value print_string "quote:start\n" drop } otherwise
    { assert "bad expression type" false 2drop . dup }
;

# <token> ->
def "expression_print" {
    expression_print_switch
    expression_get_type_id dup
} ;

print_newline
expression_print
expression_create expression_anon_func_type
keep { array_list_append dip { expression_create expression_i64_literal_type 42 } }
array_list_new
;
se_check_last_defined_function ;
    
while { true } {
    print_newline token_print read_next_token
} ;
